{
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "id": "cTmg3fjGMuV2",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Action 1 文本抄袭自动检测分析\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import jieba\n",
        "from sklearn.feature_extraction.text import CountVectorizer, TfidfTransformer\n",
        "from sklearn.model_selection import train_test_split\n",
        "\n",
        "# load stop words\n",
        "with open('C:\\Desktop\\开课吧\\BI_core\\HW3\\chinese_stopwords.txt', 'r', encoding='utf-8') as file:\n",
        "    stopwords = [i[:-1] for i in file.readlines()]\n",
        "\n",
        "# load data\n",
        "news = pd.read_csv('C:\\Desktop\\开课吧\\BI_core\\HW3\\sqlResult.csv', encoding='gb18030')\n",
        "news.head(3)\n",
        "\n",
        "# drop nan\n",
        "news = news.dropna(subset=['content'])\n",
        "print(news.shape)"
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": "(87054, 7)\n"
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {},
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": "Building prefix dict from the default dictionary ...\nDumping model to file cache E:\\AppData\\Local\\Temp\\jieba.cache\nLoading model cost 3.041 seconds.\nPrefix dict has been built succesfully.\n"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": "'此外 本周 除 小米 手机 款 机型 外 机型 暂停 更新 发布 含 开发 版 体验版 内测 稳定版 暂不受 影响 确保 工程师 集中 全部 精力 进行 系统优化 工作 有人 猜测 精力 主要 用到 MIUI9 研发 之中 MIUI8 去年 发布 距今已有 一年 有余 更新换代 当然 MIUI9 确切 信息 等待 官方消息'"
          },
          "metadata": {},
          "execution_count": 2
        }
      ],
      "source": [
        "def split_text(text):\n",
        "    '''split words'''\n",
        "    text = text.replace(' ','').replace('\\n','').replace('\\r','')\n",
        "    text2 = jieba.cut(text.strip())\n",
        "    result = ' '.join([w for w in text2 if w not in stopwords])\n",
        "    return result\n",
        "\n",
        "split_text(news.iloc[0].content)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {},
      "outputs": [],
      "source": [
        "import pickle, os\n",
        "\n",
        "if not os.path.exists('C:\\Desktop\\开课吧\\BI_core\\HW3\\corpus.pkl'):\n",
        "    # if corpus not exist, build it\n",
        "    corpus = list(map(split_text, [str(i) for i in news.content]))\n",
        "    with open('C:\\Desktop\\开课吧\\BI_core\\HW3\\corpus.pkl','wb') as file:\n",
        "        pickle.dump(corpus, file)\n",
        "else:\n",
        "    # use the existing one\n",
        "    with open('C:\\Desktop\\开课吧\\BI_core\\HW3\\corpus.pkl','rb') as file:\n",
        "        corpus = pickle.load(file)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {},
      "outputs": [],
      "source": [
        "# get TF-IDF matrix of the corpus\n",
        "countvectorizer = CountVectorizer(encoding='gb18030',  min_df=0.015)\n",
        "tfidftransformer = TfidfTransformer()\n",
        "\n",
        "countvector = countvectorizer.fit_transform(corpus)\n",
        "tfidf = tfidftransformer.fit_transform(countvector)\n",
        "\n",
        "# set label\n",
        "label = list(map(lambda source:1 if '新华' in str(source) else 0, news.source))\n",
        "\n",
        "# split dataset\n",
        "X_train, X_test, y_train, y_test = train_test_split(tfidf, label, test_size=0.3)\n",
        "\n",
        "# model and training\n",
        "from sklearn.naive_bayes import MultinomialNB\n",
        "clf = MultinomialNB()\n",
        "clf.fit(X_train, y_train)\n",
        "pred = clf.predict(tfidf)\n",
        "labels = np.array(label)\n",
        "compare_news_index = pd.DataFrame({'prediction': pred, 'labels': labels})\n",
        "\n",
        "# set a filter to get all possible copys\n",
        "copy_news_index = compare_news_index[(compare_news_index['prediction']==1) & (compare_news_index['labels']!=1)]\n",
        "true_news_index = compare_news_index[(compare_news_index['labels']==1)].index"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {},
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": "共有78855篇新华社的文章，另外有2785篇其它文章可能抄袭\n"
        }
      ],
      "source": [
        "print('共有{}篇新华社的文章，另外有{}篇其它文章可能抄袭'.format(true_news_index.shape[0], copy_news_index.shape[0]))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {},
      "outputs": [],
      "source": [
        "# data normalizer\n",
        "from sklearn.preprocessing import Normalizer\n",
        "normalizer = Normalizer()\n",
        "scaled_array = normalizer.fit_transform(tfidf)\n",
        "\n",
        "# use Kmeans for clustering\n",
        "from sklearn.cluster import KMeans\n",
        "kmeans = KMeans(n_clusters=25)\n",
        "\n",
        "# save to file\n",
        "if not os.path.exists('C:\\Desktop\\开课吧\\BI_core\\HW3\\label.pkl'):\n",
        "    with open('C:\\Desktop\\开课吧\\BI_core\\HW3\\label.pkl','wb') as file:\n",
        "        k_labels = kmeans.fit_predict(scaled_array)\n",
        "        pickle.dump(k_labels, file)\n",
        "else:\n",
        "    with open('C:\\Desktop\\开课吧\\BI_core\\HW3\\label.pkl','rb') as file:\n",
        "        k_labels = pickle.load(file)\n",
        "\n",
        "if not os.path.exists('C:\\Desktop\\开课吧\\BI_core\\HW3\\id_class.pkl'):\n",
        "    with open('C:\\Desktop\\开课吧\\BI_core\\HW3\\id_class.pkl','wb') as file:\n",
        "        id_class = {index:class_ for index, class_ in enumerate(k_labels)}\n",
        "        pickle.dump(id_class, file)\n",
        "else:\n",
        "    with open('C:\\Desktop\\开课吧\\BI_core\\HW3\\id_class.pkl','rb') as file:\n",
        "        id_class = pickle.load(file)\n",
        "\n",
        "from collections import defaultdict\n",
        "if not os.path.exists('C:\\Desktop\\开课吧\\BI_core\\HW3\\class_id.pkl'):\n",
        "    class_id = defaultdict(set)\n",
        "    for index, class_ in id_class.items():\n",
        "        # only count the true class_id\n",
        "        if index in true_news_index.tolist():\n",
        "            class_id[class_].add(index)\n",
        "        with open('C:\\Desktop\\开课吧\\BI_core\\HW3\\class_id.pkl','wb') as file:\n",
        "            pickle.dump(class_id, file)\n",
        "else:\n",
        "    with open('C:\\Desktop\\开课吧\\BI_core\\HW3\\class_id.pkl','rb') as file:\n",
        "        class_id = pickle.load(file)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {},
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": "[(3134, array([[0.96849134]])), (63511, array([[0.94643202]])), (29441, array([[0.9428342]])), (3218, array([[0.87621844]])), (980, array([[0.87535112]])), (29615, array([[0.86936332]])), (29888, array([[0.86215823]])), (64046, array([[0.85278237]])), (29777, array([[0.84875426]])), (63974, array([[0.73415186]]))]\n\n怀疑抄袭:\n 　　中国5月份56座城市新建商品住宅价格环比上涨，4月份为58座上涨。5月份15个一线和热点二线城市房地产市场基本稳定，5月份房地产调控政策效果继续显现。\n　　统计局：15个一线和热点二线城市房价同比涨幅全部回落\n　　国家统计局城市司高级统计师刘建伟解读5月份房价数据\n　　5月份一二线城市房价平均涨幅继续回落\n　　国家统计局今日发布了2017年5月份70个大中城市住宅销售价格统计数据。对此，国家统计局城市司高级统计师刘建伟进行了解读。\n　　一、15个一线和热点二线城市新建商品住宅价格同比涨幅全部回落、9个城市环比下降或持平\n　　5月份，因地制宜、因城施策的房地产调控政策效果继续显现，15个一线和热点二线城市房地产市场基本稳定。从同比看，15个城市新建商品住宅价格涨幅均比上月回落，回落幅度在0.5至6.4个百分点之间。从环比看，9个城市新建商品住宅价格下降或持平；5个城市涨幅在0.5%以内。\n　　二、70个大中城市中一二线城市房价同比涨幅持续回落\n　　5月份，70个城市中新建商品住宅和二手住宅价格同比涨幅比上月回落的城市分别有29和18个。其中，一二线城市同比涨幅回落尤其明显。据测算，一线城市新建商品住宅和二手住宅价格同比涨幅均连续8个月回落，5月份比4月份分别回落2.2和1.7个百分点；二线城市新建商品住宅和二手住宅价格同比涨幅分别连续6个月和4个月回落，5月份比4月份分别回落0.8和0.5个百分点。\n　　三、70个大中城市中房价环比下降及涨幅回落城市个数均有所增加\n　　5月份，70个城市中新建商品住宅价格环比下降的城市有9个，比上月增加1个；涨幅回落的城市有26个，比上月增加3个。二手住宅价格环比下降的城市有7个，比上月增加2个；涨幅回落的城市有30个，比上月增加8个。\n\n相似原文:\n 　　国家统计局19日发布数据，5月份，15个一线和热点二线城市新建商品住宅价格同比涨幅全部回落，其中9个城市环比下降或持平。这9个价格环比下降或持平的城市为：北京、上海、南京、杭州、合肥、福州、郑州、深圳、成都。\n　　“5月份，因地制宜、因城施策的房地产调控政策效果继续显现，15个一线和热点二线城市房地产市场基本稳定。”国家统计局城市司高级统计师刘建伟说，从同比看，15个城市新建商品住宅价格涨幅均比上月回落，回落幅度在0.5至6.4个百分点之间。从环比看，9个城市新建商品住宅价格下降或持平；5个城市涨幅在0.5%以内。\n　　国家统计局当天还发布了5月份70个大中城市住宅销售价格统计数据。刘建伟介绍，5月份，70个大中城市中新建商品住宅和二手住宅价格同比涨幅比上月回落的城市分别有29和18个。其中，一二线城市同比涨幅回落尤其明显。据测算，一线城市新建商品住宅和二手住宅价格同比涨幅均连续8个月回落，5月份比4月份分别回落2.2和1.7个百分点；二线城市新建商品住宅和二手住宅价格同比涨幅分别连续6个月和4个月回落，5月份比4月份分别回落0.8和0.5个百分点。\n　　此外，70个大中城市中房价环比下降及涨幅回落城市个数均有所增加。统计显示，5月份，70个大中城市中新建商品住宅价格环比下降的城市有9个，比上月增加1个；涨幅回落的城市有26个，比上月增加3个。二手住宅价格环比下降的城市有7个，比上月增加2个；涨幅回落的城市有30个，比上月增加8个。\n\n"
        }
      ],
      "source": [
        "from sklearn.metrics.pairwise import cosine_similarity\n",
        "# search for similar text\n",
        "def find_similar_text(cpindex, top=10):\n",
        "    # only search for articles which is released by Xinhua\n",
        "    dist = {i:cosine_similarity(tfidf[cpindex], tfidf[i]) for i in class_id[id_class[cpindex]]}\n",
        "    return sorted(dist.items(), key=lambda x:x[1][0], reverse=True)[:top]\n",
        "\n",
        "# pick one in copy_news_index\n",
        "cpindex = 3352\n",
        "similar_list = find_similar_text(cpindex)\n",
        "print(similar_list)\n",
        "print('\\n怀疑抄袭:\\n', news.iloc[cpindex].content)\n",
        "similar2 = similar_list[0][0]\n",
        "print('相似原文:\\n', news.iloc[similar2].content)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": []
    }
  ],
  "metadata": {
    "colab": {
      "name": "HW3.ipynb",
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
